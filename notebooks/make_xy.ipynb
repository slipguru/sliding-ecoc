{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.3320 - acc: 0.8988Epoch 00000: val_loss improved from inf to 0.07673, saving model to weights.h5\n",
      "60000/60000 [==============================] - 19s - loss: 0.3313 - acc: 0.8990 - val_loss: 0.0767 - val_acc: 0.9762\n",
      "Epoch 2/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9661Epoch 00001: val_loss improved from 0.07673 to 0.05196, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.1141 - acc: 0.9660 - val_loss: 0.0520 - val_acc: 0.9829\n",
      "Epoch 3/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9741Epoch 00002: val_loss improved from 0.05196 to 0.04585, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.0868 - acc: 0.9742 - val_loss: 0.0458 - val_acc: 0.9853\n",
      "Epoch 4/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9782Epoch 00003: val_loss improved from 0.04585 to 0.03655, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.0735 - acc: 0.9782 - val_loss: 0.0365 - val_acc: 0.9878\n",
      "Epoch 5/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9809Epoch 00004: val_loss improved from 0.03655 to 0.03547, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.0631 - acc: 0.9810 - val_loss: 0.0355 - val_acc: 0.9877\n",
      "Epoch 6/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9831Epoch 00005: val_loss improved from 0.03547 to 0.03318, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.0569 - acc: 0.9831 - val_loss: 0.0332 - val_acc: 0.9872\n",
      "Epoch 7/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9844Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0523 - acc: 0.9844 - val_loss: 0.0344 - val_acc: 0.9889\n",
      "Epoch 8/200\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9858Epoch 00007: val_loss improved from 0.03318 to 0.02972, saving model to weights.h5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0466 - acc: 0.9858 - val_loss: 0.0297 - val_acc: 0.9896\n",
      "Epoch 9/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9867Epoch 00008: val_loss improved from 0.02972 to 0.02934, saving model to weights.h5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0440 - acc: 0.9866 - val_loss: 0.0293 - val_acc: 0.9899\n",
      "Epoch 10/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9874Epoch 00009: val_loss improved from 0.02934 to 0.02745, saving model to weights.h5\n",
      "60000/60000 [==============================] - 17s - loss: 0.0420 - acc: 0.9874 - val_loss: 0.0274 - val_acc: 0.9905\n",
      "Epoch 11/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9880Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0403 - acc: 0.9881 - val_loss: 0.0280 - val_acc: 0.9902\n",
      "Epoch 12/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9891Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0371 - acc: 0.9891 - val_loss: 0.0276 - val_acc: 0.9910\n",
      "Epoch 13/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9897Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0348 - acc: 0.9897 - val_loss: 0.0287 - val_acc: 0.9902\n",
      "Epoch 14/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9894Epoch 00013: val_loss improved from 0.02745 to 0.02561, saving model to weights.h5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0342 - acc: 0.9894 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 15/200\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9900Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 18s - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0325 - val_acc: 0.9885\n",
      "Epoch 16/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9903Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0320 - acc: 0.9903 - val_loss: 0.0276 - val_acc: 0.9911\n",
      "Epoch 17/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9907Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0318 - acc: 0.9907 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 18/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9909Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0311 - acc: 0.9909 - val_loss: 0.0257 - val_acc: 0.9921\n",
      "Epoch 19/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9913Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0300 - acc: 0.9913 - val_loss: 0.0271 - val_acc: 0.9910\n",
      "Epoch 20/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9909Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0298 - acc: 0.9909 - val_loss: 0.0296 - val_acc: 0.9901\n",
      "Epoch 21/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9911Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0264 - val_acc: 0.9917\n",
      "Epoch 22/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9915Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0265 - acc: 0.9915 - val_loss: 0.0267 - val_acc: 0.9920\n",
      "Epoch 23/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9917Epoch 00022: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0294 - acc: 0.9916 - val_loss: 0.0257 - val_acc: 0.9921\n",
      "Epoch 24/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9918Epoch 00023: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0275 - acc: 0.9918 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 25/200\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9917Epoch 00024: val_loss did not improve\n",
      "60000/60000 [==============================] - 17s - loss: 0.0287 - acc: 0.9917 - val_loss: 0.0268 - val_acc: 0.9913\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "             ModelCheckpoint(filepath='weights.h5', verbose=1, save_best_only=True)]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9824/10000 [============================>.] - ETA: 0s\n",
      "Test loss: 0.0267864717936\n",
      "Test accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = make_model()\n",
    "base_model.load_weights('weights.h5')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,\n",
    "                 weights=base_model.layers[0].get_weights()))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', weights=base_model.layers[1].get_weights()))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), weights=base_model.layers[2].get_weights()))\n",
    "model.add(Dropout(0.25, weights=base_model.layers[3].get_weights()))\n",
    "model.add(Flatten(weights=base_model.layers[4].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_activations = model.predict(x_train)\n",
    "x_test_activations = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', x_train_activations)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('X_test.npy', x_test_activations)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
